{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f628971c",
   "metadata": {},
   "source": [
    "# Dataset Creation Notebook\n",
    "\n",
    "This notebook collects stimuli for a psycholinguistic experiment on emotionally valent words and their perception (via reaction times).\n",
    "\n",
    "> Code by: \\\n",
    "*Jasmin Orth, LMU Munich*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cac5c8e",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "In this notebook, we read from three datasets in total:\n",
    "* [`BRM-emot-submit.csv`](https://link.springer.com/article/10.3758/s13428-012-0314-x): This dataset gives us our stimuli and their emotional valence $\\to$ `stimuli_and_valence_df`\n",
    "* [`SUBTLEXusfrequencyabove1.xls`](https://www.ugent.be/pp/experimentele-psychologie/en/research/documents/subtlexus/overview.htm): This dataset gives us frequencies of words $\\to$ `freq_df`\n",
    "* [`CogNet-v1.0.tsv`](https://github.com/kbatsuren/CogNet/blob/master/CogNet-v1.0.zip): this dataset gives us words and their cognates from any language $\\to$ `cognate_df`\n",
    "\n",
    "We will take our potential stimuli from the `stimuli_and_valence_df`. Then, by checking against pre-set conditions, we only retain the ones that meet them. The resulting stimuli (words) are categorized into positive, negative, and neutral, depending on their valence values.\n",
    "\n",
    "> Note: we are parsing pretty big datasets here, so some parts of this notebook might take a while to run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16808496",
   "metadata": {},
   "source": [
    "### Conditions For Words To Be Included:\n",
    "\n",
    "* length shorter than 8 characters (i.e. maximum 7 characters long)\n",
    "* part-of-speech (POS) is noun\n",
    "* log frequency is higher than 2\n",
    "* non-cognates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5018d2b8",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130aa1f5",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad38a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81c8c75",
   "metadata": {},
   "source": [
    "### Load Datasets\n",
    "We read the datasets that we have collected (i.e., downloaded).\n",
    "> If you run this, make sure they are in the same folder as this code notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "741c5665",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli_and_valence_df = pd.read_csv(\"BRM-emot-submit.csv\", index_col=0)        # stimuli, emotional valence\n",
    "freq_df = pd.read_excel(\"SUBTLEXusfrequencyabove1.xls\")        # frequency\n",
    "cognate_df = pd.read_csv(\"CogNet-v1.0.tsv\", sep=\"\\t\")        # cognate status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0820da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to see our datasets\n",
    "print(f\" Stimuli Dataset: \\n {stimuli_and_valence_df[:3]} \\n\")\n",
    "print(f\"Freguency Dataset: \\n {freq_df[:3]} \\n\")\n",
    "print(f\"Cognate Dataset: \\n {cognate_df[:3]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c7cc25",
   "metadata": {},
   "source": [
    "## Process Datasets\n",
    "\n",
    "We will now parse the datasets we loaded. Then we take everything we need from them (e.g., frequencies) and/or perform preprocessing (e.g., POS tagging).\n",
    "\n",
    "> We do this in advance because the datasets are pretty big and this helps with computation time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a72ed0",
   "metadata": {},
   "source": [
    "### Precompute Frequency Dictionary\n",
    "\n",
    "We parse our frequency dataset and take only the \"Lg10WF\" frequencies from it. We then save them in a dictionary to be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ef40d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = dict(zip(freq_df[\"Word\"].astype(str), freq_df[\"Lg10WF\"])) # e.g., {\"dog\": 2.111, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf977570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to see our frequency dictionary\n",
    "freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf13bcd",
   "metadata": {},
   "source": [
    "### Precompute POS Tags For All Stimuli\n",
    "\n",
    "We parse our stimuli dataset and assign POS tags (**P**art-**O**f-**S**peech **T**ags, i.e., *Wortarten*). \\\n",
    "We use the so-called `pos_tag` method from NLTK (**N**atural **L**anguage **T**ool**K**it) to get POS tags for all of our potential words. We then save them in a dictionary to be used later.\n",
    "\n",
    "> Note: \\\n",
    "This is a very basic method for assigning POS tags, so we will have to check our data manually later to find potential mistakes. \\\n",
    "$\\to$ but it's the easiest and quickest way to do this, especially for nouns (like in our case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b104127",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli = stimuli_and_valence_df[\"Word\"].astype(str).tolist()\n",
    "tagged = dict(nltk.pos_tag(stimuli))   # e.g., {\"dog\": \"NN\", ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5944a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to see our POS dictionary\n",
    "tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdbb3ae",
   "metadata": {},
   "source": [
    "### Precompute Cognate Lookup\n",
    "\n",
    "We parse the cognate dataset. Cognates in this dataset are shown as `word1`, `language1` and the corresponding `word2`, `language2` (in one row). \\\n",
    "As we are interested in English-German cognates, we only take the rows of the dataset where either `language1` or `language2` is English and the other one is German.\n",
    "\n",
    "> Note: \\\n",
    "For now, we will assume that anything that is not in the cognate dataset is actually not a cognate. \\\n",
    "This does not necessarily filter out **all** cognates. It could be the case that a word is simply not present in the dataset even though it is a cognate. We will manually check the dataset later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258c0dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# big dataset -> running this will take some time\n",
    "cognate_set = set()\n",
    "\n",
    "for _, r in cognate_df.iterrows():\n",
    "    w1, l1 = r[\"word 1\"], r[\"lang 1\"]   # e.g. w1: \"cat\", l1: \"eng\", w2: \"Katze\", l2: \"deu\"\n",
    "    w2, l2 = r[\"word 2\"], r[\"lang 2\"]\n",
    "\n",
    "    if l1 == \"eng\" and l2 == \"deu\":\n",
    "        cognate_set.add(str(w1))\n",
    "    if l2 == \"eng\" and l1 == \"deu\":\n",
    "        cognate_set.add(str(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e846f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to see our cognate set\n",
    "cognate_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d5d8e7",
   "metadata": {},
   "source": [
    "## Final Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2802873",
   "metadata": {},
   "source": [
    "### Process Rows\n",
    "\n",
    "Now that we have prepared everything that we need, we can start processing our dataset.\n",
    "This means that for each word, we check our dataset conditions (through the `if`-statements).\n",
    "\n",
    "<small>\n",
    "\n",
    "**Reminder** - these are our dataset conditions:\n",
    "* length shorter than 8 characters (i.e. maximum 7 characters long)\n",
    "* part-of-speech (POS) is noun\n",
    "* log frequency is higher than 2\n",
    "* non-cognates\n",
    "\n",
    "</small>\n",
    "\n",
    "If any of these conditions are not met, we \"`continue`\", which means that the word will dropped (i.e., not be added to the dataset) and we continue with the next one.\n",
    "\n",
    "If the word passed all the checks, we look up its emotional valence and assign a categorical value to it (`positive`/`negative`/`neutral`)\n",
    "* **positive**: continuous valence of 7 or higher\n",
    "* **negative**: continuous valence of 3 or lower\n",
    "* **neutral**: continuous valence between (or equal to) 4.5 and 5.5\n",
    "\n",
    "Everything that falls outside of this range will be left out of the dataset, because we want there to be be clear distinctions between the valences. \\\n",
    "$\\to$ We dont want fuzzy boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af75bd6",
   "metadata": {},
   "source": [
    "#### Idea Behind The Code\n",
    "\n",
    "> You can imagine the following code like words literally trying to walk through it top to bottom. If a condition is not met, its journey stops and the next word tries its luck. If a word makes it to the bottom, we can save it. Basically a decision tree:\n",
    "\n",
    "<img src=\"dec_tree.png\" width=\"200\">\n",
    "\n",
    "<small>(increase the `width` of this image to $\\approx$ 500 see it better)<small>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332e43a3",
   "metadata": {},
   "source": [
    "### Adding Words\n",
    "After doing all that, we will add the word to our dataset, along with all the info that we have collected about it along the way:\n",
    "\n",
    "* `\"Stimulus\": stimulus.upper(),` $\\to$ the word itself (all upper case)\n",
    "* `\"Condition\": \"word\",` $\\to$ in contrast to *non-words*, which we will add to our dataset separately\n",
    "* `\"Cognate_status\": \"noncognate\",` $\\to$ all our words should be non-cognates\n",
    "* `\"Emotional_valence_cat\": cat_valence,` $\\to$ the assigned categorical valence (positive/negative/neutral)\n",
    "* `\"Emotional_valence_cont\": valence,` $\\to$ the original continuous valence of the word\n",
    "* `\"Length\": len(stimulus),` $\\to$ the length of the word\n",
    "* `\"Lg10SUBTLEX_US\": freq,` $\\to$ the frequency of the word\n",
    "* `\"correct_response\": \"j\"` $\\to$ for words, the correct response is always \"j\" (in contrast to \"f\" for *non-words*)\n",
    "\n",
    "> Note: \\\n",
    "We also count how many of each valence we have: \\\n",
    "Whilst we want to have 30 of each in the end, ideally, at this point, the numbers should be higher. \\\n",
    "This is because we want to go over the dataset manually later (to account for any potential mistakes with POS and non-cognate assignments).\n",
    "We also want to make sure that we only have clear-valence-words in there, so we will check that manually too. \\\n",
    "Therefore, the **numbers should be high enough to account for any manual post-hoc deletions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "25776426",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "neg_count = pos_count = neutr_count = none_count = 0\n",
    "\n",
    "for _, row in stimuli_and_valence_df.iterrows():\n",
    "    stimulus = str(row[\"Word\"])\n",
    "    valence = row[\"V.Mean.Sum\"]\n",
    "\n",
    "    # length filter: discard everything longer then 7 chararacters\n",
    "    if len(stimulus) > 7:\n",
    "        none_count += 1\n",
    "        continue\n",
    "\n",
    "    # POS filter: discard verything that is not a noun\n",
    "    tag = tagged.get(stimulus, \"\")\n",
    "    if not tag.startswith(\"NN\"):\n",
    "        none_count += 1\n",
    "        continue\n",
    "\n",
    "    # frequency filter: discard everything that has a smaller log frequency than 2\n",
    "    freq = freq_dict.get(stimulus, 0) # If a word does not exist in the frequency dataset, we assume its frequency is 0\n",
    "    if freq <= 2:\n",
    "        none_count += 1\n",
    "        continue\n",
    "\n",
    "    # cognate check: discard all cognates\n",
    "    if stimulus in cognate_set:\n",
    "        none_count += 1\n",
    "        continue\n",
    "\n",
    "    # process valence into categorical (cat_valence) and continuuos (valence)\n",
    "    # increase the valence counters accordingly\n",
    "    cat_valence = None\n",
    "\n",
    "    if valence <= 3:\n",
    "        cat_valence = \"negative\"\n",
    "        neg_count += 1\n",
    "\n",
    "    elif valence >= 7:\n",
    "        cat_valence = \"positive\"\n",
    "        pos_count += 1\n",
    "\n",
    "    elif 4.5 <= valence <= 5.5:\n",
    "        cat_valence = \"neutral\"\n",
    "        neutr_count += 1\n",
    "\n",
    "    else:\n",
    "        valence = None\n",
    "        none_count += 1\n",
    "        continue            # skip fuzzy boundary cases\n",
    "\n",
    "    # add the word\n",
    "    if pd.notna(valence):\n",
    "        rows.append({\n",
    "            \"Experiment\": \"LDT\",\n",
    "            \"Item_type\": \"exp\",\n",
    "            \"Stimulus\": stimulus.upper(),\n",
    "            \"Condition\": \"word\",\n",
    "            \"Cognate_status\": \"noncognate\",\n",
    "            \"Emotional_valence_cat\": cat_valence,\n",
    "            \"Emotional_valence_cont\": valence,\n",
    "            \"Length\": len(stimulus),\n",
    "            \"Lg10SUBTLEX_US\": freq,\n",
    "            \"correct_response\": \"j\"\n",
    "        })\n",
    "\n",
    "exp_df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e57de33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 142, Negative: 179, Neutral: 595. \n",
      "\n",
      "We have discarded 12999 words so far!\n"
     ]
    }
   ],
   "source": [
    "# run to see how many words we have in each category\n",
    "print(f\"Positive: {pos_count}, Negative: {neg_count}, Neutral: {neutr_count}. \\n\\nWe have discarded {none_count} words so far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "716b0114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Item_type</th>\n",
       "      <th>Stimulus</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Cognate_status</th>\n",
       "      <th>Emotional_valence_cat</th>\n",
       "      <th>Emotional_valence_cont</th>\n",
       "      <th>Length</th>\n",
       "      <th>Lg10SUBTLEX_US</th>\n",
       "      <th>correct_response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LDT</td>\n",
       "      <td>exp</td>\n",
       "      <td>ABDOMEN</td>\n",
       "      <td>word</td>\n",
       "      <td>noncognate</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5.43</td>\n",
       "      <td>7</td>\n",
       "      <td>2.235528</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LDT</td>\n",
       "      <td>exp</td>\n",
       "      <td>ABILITY</td>\n",
       "      <td>word</td>\n",
       "      <td>noncognate</td>\n",
       "      <td>positive</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7</td>\n",
       "      <td>2.991669</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LDT</td>\n",
       "      <td>exp</td>\n",
       "      <td>ABSORB</td>\n",
       "      <td>word</td>\n",
       "      <td>noncognate</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5.50</td>\n",
       "      <td>6</td>\n",
       "      <td>2.008600</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LDT</td>\n",
       "      <td>exp</td>\n",
       "      <td>ABUSE</td>\n",
       "      <td>word</td>\n",
       "      <td>noncognate</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.53</td>\n",
       "      <td>5</td>\n",
       "      <td>2.719331</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LDT</td>\n",
       "      <td>exp</td>\n",
       "      <td>ACCOUNT</td>\n",
       "      <td>word</td>\n",
       "      <td>noncognate</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5.39</td>\n",
       "      <td>7</td>\n",
       "      <td>3.358125</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>LDT</td>\n",
       "      <td>exp</td>\n",
       "      <td>YEN</td>\n",
       "      <td>word</td>\n",
       "      <td>noncognate</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2.495544</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>LDT</td>\n",
       "      <td>exp</td>\n",
       "      <td>YUMMY</td>\n",
       "      <td>word</td>\n",
       "      <td>noncognate</td>\n",
       "      <td>positive</td>\n",
       "      <td>7.52</td>\n",
       "      <td>5</td>\n",
       "      <td>2.359835</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>LDT</td>\n",
       "      <td>exp</td>\n",
       "      <td>ZAP</td>\n",
       "      <td>word</td>\n",
       "      <td>noncognate</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5.39</td>\n",
       "      <td>3</td>\n",
       "      <td>2.100371</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>LDT</td>\n",
       "      <td>exp</td>\n",
       "      <td>ZIP</td>\n",
       "      <td>word</td>\n",
       "      <td>noncognate</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5.06</td>\n",
       "      <td>3</td>\n",
       "      <td>2.591065</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>LDT</td>\n",
       "      <td>exp</td>\n",
       "      <td>ZIPPER</td>\n",
       "      <td>word</td>\n",
       "      <td>noncognate</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5.11</td>\n",
       "      <td>6</td>\n",
       "      <td>2.161368</td>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>916 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Experiment Item_type Stimulus Condition Cognate_status  \\\n",
       "0          LDT       exp  ABDOMEN      word     noncognate   \n",
       "1          LDT       exp  ABILITY      word     noncognate   \n",
       "2          LDT       exp   ABSORB      word     noncognate   \n",
       "3          LDT       exp    ABUSE      word     noncognate   \n",
       "4          LDT       exp  ACCOUNT      word     noncognate   \n",
       "..         ...       ...      ...       ...            ...   \n",
       "911        LDT       exp      YEN      word     noncognate   \n",
       "912        LDT       exp    YUMMY      word     noncognate   \n",
       "913        LDT       exp      ZAP      word     noncognate   \n",
       "914        LDT       exp      ZIP      word     noncognate   \n",
       "915        LDT       exp   ZIPPER      word     noncognate   \n",
       "\n",
       "    Emotional_valence_cat  Emotional_valence_cont  Length  Lg10SUBTLEX_US  \\\n",
       "0                 neutral                    5.43       7        2.235528   \n",
       "1                positive                    7.00       7        2.991669   \n",
       "2                 neutral                    5.50       6        2.008600   \n",
       "3                negative                    1.53       5        2.719331   \n",
       "4                 neutral                    5.39       7        3.358125   \n",
       "..                    ...                     ...     ...             ...   \n",
       "911               neutral                    5.00       3        2.495544   \n",
       "912              positive                    7.52       5        2.359835   \n",
       "913               neutral                    5.39       3        2.100371   \n",
       "914               neutral                    5.06       3        2.591065   \n",
       "915               neutral                    5.11       6        2.161368   \n",
       "\n",
       "    correct_response  \n",
       "0                  j  \n",
       "1                  j  \n",
       "2                  j  \n",
       "3                  j  \n",
       "4                  j  \n",
       "..               ...  \n",
       "911                j  \n",
       "912                j  \n",
       "913                j  \n",
       "914                j  \n",
       "915                j  \n",
       "\n",
       "[916 rows x 10 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run to see our final dataset\n",
    "exp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc67a8b",
   "metadata": {},
   "source": [
    "### Save The Dataset\n",
    "\n",
    "We can now save the dataset to a `.csv` file.\n",
    "\n",
    "> Important: \\\n",
    "If you already have a file saved under the same name, this **will overwrite it**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2822fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! The dataset was saved to \"dataframe_exp.csv\". Check your folder :)\n"
     ]
    }
   ],
   "source": [
    "exp_df.to_csv(\"dataframe_exp.csv\", encoding='utf-8', index=False, sep = \";\")\n",
    "print(f\"Done! The dataset was saved to \\\"dataframe_exp.csv\\\". Check your folder :)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
